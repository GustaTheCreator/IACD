{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bcce3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gugaa\\desktop\\iacd\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn pandas numpy ucimlrepo joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "179eedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb5aa164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 45, 'name': 'Heart Disease', 'repository_url': 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'data_url': 'https://archive.ics.uci.edu/static/public/45/data.csv', 'abstract': '4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 303, 'num_features': 13, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': ['Age', 'Sex'], 'target_col': ['num'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1989, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C52P4X', 'creators': ['Andras Janosi', 'William Steinbrunn', 'Matthias Pfisterer', 'Robert Detrano'], 'intro_paper': {'ID': 231, 'type': 'NATIVE', 'title': 'International application of a new probability algorithm for the diagnosis of coronary artery disease.', 'authors': 'R. Detrano, A. Jánosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, V. Froelicher', 'venue': 'American Journal of Cardiology', 'year': 1989, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/a7d714f8f87bfc41351eb5ae1e5472f0ebbe0574', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': '2756873', 'pmcid': None}, 'additional_info': {'summary': 'This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to date.  The \"goal\" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \\n   \\nThe names and social security numbers of the patients were recently removed from the database, replaced with dummy values.\\n\\nOne file has been \"processed\", that one containing the Cleveland database.  All four unprocessed files also exist in this directory.\\n\\nTo see Test Costs (donated by Peter Turney), please see the folder \"Costs\" ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Only 14 attributes used:\\r\\n      1. #3  (age)       \\r\\n      2. #4  (sex)       \\r\\n      3. #9  (cp)        \\r\\n      4. #10 (trestbps)  \\r\\n      5. #12 (chol)      \\r\\n      6. #16 (fbs)       \\r\\n      7. #19 (restecg)   \\r\\n      8. #32 (thalach)   \\r\\n      9. #38 (exang)     \\r\\n      10. #40 (oldpeak)   \\r\\n      11. #41 (slope)     \\r\\n      12. #44 (ca)        \\r\\n      13. #51 (thal)      \\r\\n      14. #58 (num)       (the predicted attribute)\\r\\n\\r\\nComplete attribute documentation:\\r\\n      1 id: patient identification number\\r\\n      2 ccf: social security number (I replaced this with a dummy value of 0)\\r\\n      3 age: age in years\\r\\n      4 sex: sex (1 = male; 0 = female)\\r\\n      5 painloc: chest pain location (1 = substernal; 0 = otherwise)\\r\\n      6 painexer (1 = provoked by exertion; 0 = otherwise)\\r\\n      7 relrest (1 = relieved after rest; 0 = otherwise)\\r\\n      8 pncaden (sum of 5, 6, and 7)\\r\\n      9 cp: chest pain type\\r\\n        -- Value 1: typical angina\\r\\n        -- Value 2: atypical angina\\r\\n        -- Value 3: non-anginal pain\\r\\n        -- Value 4: asymptomatic\\r\\n     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)\\r\\n     11 htn\\r\\n     12 chol: serum cholestoral in mg/dl\\r\\n     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\\r\\n     14 cigs (cigarettes per day)\\r\\n     15 years (number of years as a smoker)\\r\\n     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\\r\\n     17 dm (1 = history of diabetes; 0 = no such history)\\r\\n     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\\r\\n     19 restecg: resting electrocardiographic results\\r\\n        -- Value 0: normal\\r\\n        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\\r\\n        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes\\' criteria\\r\\n     20 ekgmo (month of exercise ECG reading)\\r\\n     21 ekgday(day of exercise ECG reading)\\r\\n     22 ekgyr (year of exercise ECG reading)\\r\\n     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\\r\\n     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\\r\\n     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\\r\\n     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\\r\\n     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\\r\\n     28 proto: exercise protocol\\r\\n          1 = Bruce     \\r\\n          2 = Kottus\\r\\n          3 = McHenry\\r\\n          4 = fast Balke\\r\\n          5 = Balke\\r\\n          6 = Noughton \\r\\n          7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was written!)\\r\\n          8 = bike 125 kpa min/min  \\r\\n          9 = bike 100 kpa min/min\\r\\n         10 = bike 75 kpa min/min\\r\\n         11 = bike 50 kpa min/min\\r\\n         12 = arm ergometer\\r\\n     29 thaldur: duration of exercise test in minutes\\r\\n     30 thaltime: time when ST measure depression was noted\\r\\n     31 met: mets achieved\\r\\n     32 thalach: maximum heart rate achieved\\r\\n     33 thalrest: resting heart rate\\r\\n     34 tpeakbps: peak exercise blood pressure (first of 2 parts)\\r\\n     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\\r\\n     36 dummy\\r\\n     37 trestbpd: resting blood pressure\\r\\n     38 exang: exercise induced angina (1 = yes; 0 = no)\\r\\n     39 xhypo: (1 = yes; 0 = no)\\r\\n     40 oldpeak = ST depression induced by exercise relative to rest\\r\\n     41 slope: the slope of the peak exercise ST segment\\r\\n        -- Value 1: upsloping\\r\\n        -- Value 2: flat\\r\\n        -- Value 3: downsloping\\r\\n     42 rldv5: height at rest\\r\\n     43 rldv5e: height at peak exercise\\r\\n     44 ca: number of major vessels (0-3) colored by flourosopy\\r\\n     45 restckm: irrelevant\\r\\n     46 exerckm: irrelevant\\r\\n     47 restef: rest raidonuclid (sp?) ejection fraction\\r\\n     48 restwm: rest wall (sp?) motion abnormality\\r\\n        0 = none\\r\\n        1 = mild or moderate\\r\\n        2 = moderate or severe\\r\\n        3 = akinesis or dyskmem (sp?)\\r\\n     49 exeref: exercise radinalid (sp?) ejection fraction\\r\\n     50 exerwm: exercise wall (sp?) motion \\r\\n     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\\r\\n     52 thalsev: not used\\r\\n     53 thalpul: not used\\r\\n     54 earlobe: not used\\r\\n     55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\\r\\n     56 cday: day of cardiac cath (sp?)\\r\\n     57 cyr: year of cardiac cath (sp?)\\r\\n     58 num: diagnosis of heart disease (angiographic disease status)\\r\\n        -- Value 0: < 50% diameter narrowing\\r\\n        -- Value 1: > 50% diameter narrowing\\r\\n        (in any major vessel: attributes 59 through 68 are vessels)\\r\\n     59 lmt\\r\\n     60 ladprox\\r\\n     61 laddist\\r\\n     62 diag\\r\\n     63 cxmain\\r\\n     64 ramus\\r\\n     65 om1\\r\\n     66 om2\\r\\n     67 rcaprox\\r\\n     68 rcadist\\r\\n     69 lvx1: not used\\r\\n     70 lvx2: not used\\r\\n     71 lvx3: not used\\r\\n     72 lvx4: not used\\r\\n     73 lvf: not used\\r\\n     74 cathef: not used\\r\\n     75 junk: not used\\r\\n     76 name: last name of patient  (I replaced this with the dummy string \"name\")', 'citation': None}}\n",
      "        name     role         type demographic  \\\n",
      "0        age  Feature      Integer         Age   \n",
      "1        sex  Feature  Categorical         Sex   \n",
      "2         cp  Feature  Categorical        None   \n",
      "3   trestbps  Feature      Integer        None   \n",
      "4       chol  Feature      Integer        None   \n",
      "5        fbs  Feature  Categorical        None   \n",
      "6    restecg  Feature  Categorical        None   \n",
      "7    thalach  Feature      Integer        None   \n",
      "8      exang  Feature  Categorical        None   \n",
      "9    oldpeak  Feature      Integer        None   \n",
      "10     slope  Feature  Categorical        None   \n",
      "11        ca  Feature      Integer        None   \n",
      "12      thal  Feature  Categorical        None   \n",
      "13       num   Target      Integer        None   \n",
      "\n",
      "                                          description  units missing_values  \n",
      "0                                                None  years             no  \n",
      "1                                                None   None             no  \n",
      "2                                                None   None             no  \n",
      "3   resting blood pressure (on admission to the ho...  mm Hg             no  \n",
      "4                                   serum cholestoral  mg/dl             no  \n",
      "5                     fasting blood sugar > 120 mg/dl   None             no  \n",
      "6                                                None   None             no  \n",
      "7                         maximum heart rate achieved   None             no  \n",
      "8                             exercise induced angina   None             no  \n",
      "9   ST depression induced by exercise relative to ...   None             no  \n",
      "10                                               None   None             no  \n",
      "11  number of major vessels (0-3) colored by flour...   None            yes  \n",
      "12                                               None   None            yes  \n",
      "13                         diagnosis of heart disease   None             no  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(heart_disease.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(heart_disease.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d858712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados:\n",
      "X: (303, 13)\n",
      "y: (303, 1)\n",
      "\n",
      "Primeiras linhas de X:\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "    ca  thal  \n",
      "0  0.0   6.0  \n",
      "1  3.0   3.0  \n",
      "2  2.0   7.0  \n",
      "3  0.0   3.0  \n",
      "4  0.0   3.0  \n",
      "\n",
      "Primeiras linhas de y:\n",
      "   num\n",
      "0    0\n",
      "1    2\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "\n",
      "Informações sobre os dados:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        299 non-null    float64\n",
      " 12  thal      301 non-null    float64\n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.9 KB\n",
      "None\n",
      "\n",
      "Valores missing:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "dtype: int64\n",
      "\n",
      "Distribuição da variável target:\n",
      "num\n",
      "0      164\n",
      "1       55\n",
      "2       36\n",
      "3       35\n",
      "4       13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploração inicial dos dados\n",
    "print(\"Shape dos dados:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "print(\"\\nPrimeiras linhas de X:\")\n",
    "print(X.head())\n",
    "print(\"\\nPrimeiras linhas de y:\")\n",
    "print(y.head())\n",
    "print(\"\\nInformações sobre os dados:\")\n",
    "print(X.info())\n",
    "print(\"\\nValores missing:\")\n",
    "print(X.isnull().sum())\n",
    "print(\"\\nDistribuição da variável target:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b6d1c",
   "metadata": {},
   "source": [
    "## Limpeza e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3afb5473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores missing antes da limpeza:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "dtype: int64\n",
      "\n",
      "Shape após limpeza: (297, 13)\n",
      "Linhas removidas: 6\n",
      "\n",
      "Tipos de dados:\n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca          float64\n",
      "thal        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Limpeza básica dos dados\n",
    "# Criar cópia para trabalhar\n",
    "df = X.copy()\n",
    "target = y.copy()\n",
    "\n",
    "# Verificar e tratar valores missing\n",
    "print(\"Valores missing antes da limpeza:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remover linhas com valores missing (estratégia simples)\n",
    "# Alternativamente, poderia usar imputação\n",
    "df_clean = df.dropna()\n",
    "target_clean = target.loc[df_clean.index]\n",
    "\n",
    "print(f\"\\nShape após limpeza: {df_clean.shape}\")\n",
    "print(f\"Linhas removidas: {len(df) - len(df_clean)}\")\n",
    "\n",
    "# Verificar tipos de dados e converter se necessário\n",
    "print(\"\\nTipos de dados:\")\n",
    "print(df_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22876a2c",
   "metadata": {},
   "source": [
    "## Split Train/Test e Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31d54fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição do target binário:\n",
      "Sem doença (0): 160\n",
      "Com doença (1): 137\n",
      "\n",
      "Tamanho do conjunto de treino: (237, 13)\n",
      "Tamanho do conjunto de teste: (60, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preparar target (assumindo que tem valores 0-4, converter para binário)\n",
    "# 0 = sem doença, 1-4 = com doença\n",
    "y_binary = (target_clean.values.ravel() > 0).astype(int)\n",
    "\n",
    "print(f\"Distribuição do target binário:\")\n",
    "print(f\"Sem doença (0): {sum(y_binary == 0)}\")\n",
    "print(f\"Com doença (1): {sum(y_binary == 1)}\")\n",
    "\n",
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_clean, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "print(f\"\\nTamanho do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b8ae335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados com StandardScaler\n"
     ]
    }
   ],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dados normalizados com StandardScaler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b92e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Random Forest...\n",
      "\n",
      "==================================================\n",
      "RANDOM FOREST - Resultados:\n",
      "==================================================\n",
      "Acurácia: 0.8667\n",
      "ROC AUC: 0.9420\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sem Doença       0.85      0.91      0.88        32\n",
      "  Com Doença       0.88      0.82      0.85        28\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.87      0.86      0.87        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29  3]\n",
      " [ 5 23]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar modelo Random Forest\n",
    "print(\"Treinando Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predições\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RANDOM FOREST - Resultados:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Acurácia: {accuracy_rf:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_rf:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Sem Doença', 'Com Doença']))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a21cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Logistic Regression...\n",
      "\n",
      "==================================================\n",
      "LOGISTIC REGRESSION - Resultados:\n",
      "==================================================\n",
      "Acurácia: 0.8333\n",
      "ROC AUC: 0.9498\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sem Doença       0.82      0.88      0.85        32\n",
      "  Com Doença       0.85      0.79      0.81        28\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.83      0.83      0.83        60\n",
      "weighted avg       0.83      0.83      0.83        60\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28  4]\n",
      " [ 6 22]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar modelo Logistic Regression (para comparação)\n",
    "print(\"Treinando Logistic Regression...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predições\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"LOGISTIC REGRESSION - Resultados:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Acurácia: {accuracy_lr:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lr:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Sem Doença', 'Com Doença']))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91996871",
   "metadata": {},
   "source": [
    "## Guardar Modelo e Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c4ac820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo: LogisticRegression\n",
      "Acurácia: 0.8333\n",
      "ROC AUC: 0.9498\n",
      "\n",
      "Modelo guardado em: heart_disease_model.pkl\n",
      "Scaler guardado em: scaler.pkl\n",
      "Feature names guardados em: feature_names.pkl\n"
     ]
    }
   ],
   "source": [
    "# Selecionar o melhor modelo (baseado em ROC AUC)\n",
    "if roc_auc_rf >= roc_auc_lr:\n",
    "    best_model = rf_model\n",
    "    best_model_name = \"RandomForest\"\n",
    "    best_accuracy = accuracy_rf\n",
    "    best_roc_auc = roc_auc_rf\n",
    "else:\n",
    "    best_model = lr_model\n",
    "    best_model_name = \"LogisticRegression\"\n",
    "    best_accuracy = accuracy_lr\n",
    "    best_roc_auc = roc_auc_lr\n",
    "\n",
    "print(f\"Melhor modelo: {best_model_name}\")\n",
    "print(f\"Acurácia: {best_accuracy:.4f}\")\n",
    "print(f\"ROC AUC: {best_roc_auc:.4f}\")\n",
    "\n",
    "# Guardar modelo e scaler\n",
    "joblib.dump(best_model, 'heart_disease_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Guardar também os nomes das features para referência\n",
    "feature_names = df_clean.columns.tolist()\n",
    "joblib.dump(feature_names, 'feature_names.pkl')\n",
    "\n",
    "print(f\"\\nModelo guardado em: heart_disease_model.pkl\")\n",
    "print(f\"Scaler guardado em: scaler.pkl\")\n",
    "print(f\"Feature names guardados em: feature_names.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c6c1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d89b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartDiseasePredictor:\n",
    "    \"\"\"Classe para fazer predições de doença cardíaca\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='heart_disease_model.pkl', \n",
    "                 scaler_path='scaler.pkl',\n",
    "                 feature_names_path='feature_names.pkl'):\n",
    "        \"\"\"\n",
    "        Inicializa o preditor carregando o modelo e scaler\n",
    "        \n",
    "        Args:\n",
    "            model_path: Caminho para o ficheiro do modelo\n",
    "            scaler_path: Caminho para o ficheiro do scaler\n",
    "            feature_names_path: Caminho para os nomes das features\n",
    "        \"\"\"\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.scaler = joblib.load(scaler_path)\n",
    "        self.feature_names = joblib.load(feature_names_path)\n",
    "        \n",
    "        print(f\"Modelo carregado: {type(self.model).__name__}\")\n",
    "        print(f\"Features esperadas ({len(self.feature_names)}): {self.feature_names}\")\n",
    "    \n",
    "    def predict(self, features: Union[np.ndarray, pd.DataFrame, List, Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        Faz predição sobre as features fornecidas\n",
    "        \n",
    "        Args:\n",
    "            features: Features do paciente (array, DataFrame, lista ou dicionário)\n",
    "        \n",
    "        Returns:\n",
    "            Dicionário com a predição e probabilidade\n",
    "        \"\"\"\n",
    "        # Converter para DataFrame se necessário\n",
    "        if isinstance(features, dict):\n",
    "            features_df = pd.DataFrame([features])\n",
    "        elif isinstance(features, list):\n",
    "            features_df = pd.DataFrame([features], columns=self.feature_names)\n",
    "        elif isinstance(features, np.ndarray):\n",
    "            if features.ndim == 1:\n",
    "                features = features.reshape(1, -1)\n",
    "            features_df = pd.DataFrame(features, columns=self.feature_names)\n",
    "        elif isinstance(features, pd.DataFrame):\n",
    "            features_df = features\n",
    "        else:\n",
    "            raise ValueError(\"Formato de features não suportado\")\n",
    "        \n",
    "        # Validar que temos todas as features necessárias\n",
    "        if not all(col in features_df.columns for col in self.feature_names):\n",
    "            missing = [col for col in self.feature_names if col not in features_df.columns]\n",
    "            raise ValueError(f\"Features em falta: {missing}\")\n",
    "        \n",
    "        # Ordenar colunas na ordem correta\n",
    "        features_df = features_df[self.feature_names]\n",
    "        \n",
    "        # Normalizar\n",
    "        features_scaled = self.scaler.transform(features_df)\n",
    "        \n",
    "        # Predição\n",
    "        prediction = self.model.predict(features_scaled)[0]\n",
    "        probability = self.model.predict_proba(features_scaled)[0]\n",
    "        \n",
    "        # Resultado\n",
    "        result = {\n",
    "            'prediction': int(prediction),\n",
    "            'resultado': 'TEM doença cardíaca' if prediction == 1 else 'NÃO TEM doença cardíaca',\n",
    "            'probabilidade_sem_doenca': float(probability[0]),\n",
    "            'probabilidade_com_doenca': float(probability[1]),\n",
    "            'confianca': float(max(probability))\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(self, features_list: Union[pd.DataFrame, List[Dict]]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Faz predições em lote\n",
    "        \n",
    "        Args:\n",
    "            features_list: Lista de features ou DataFrame\n",
    "        \n",
    "        Returns:\n",
    "            Lista de dicionários com predições\n",
    "        \"\"\"\n",
    "        if isinstance(features_list, pd.DataFrame):\n",
    "            return [self.predict(row.to_dict()) for _, row in features_list.iterrows()]\n",
    "        else:\n",
    "            return [self.predict(features) for features in features_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c581c5d",
   "metadata": {},
   "source": [
    "## Exemplos de Uso do Preditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67ac5eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado: LogisticRegression\n",
      "Features esperadas (13): ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
      "\n",
      "======================================================================\n",
      "EXEMPLO DE USO DO PREDITOR\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Carregar o preditor\n",
    "predictor = HeartDiseasePredictor()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXEMPLO DE USO DO PREDITOR\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68adf545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Predição com dicionário:\n",
      "Resultado: NÃO TEM doença cardíaca\n",
      "Probabilidade de doença: 2.75%\n",
      "Confiança: 97.25%\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 1: Predição com dicionário\n",
    "print(\"\\n1. Predição com dicionário:\")\n",
    "paciente1 = {\n",
    "    'age': 63,\n",
    "    'sex': 1,\n",
    "    'cp': 3,\n",
    "    'trestbps': 145,\n",
    "    'chol': 233,\n",
    "    'fbs': 1,\n",
    "    'restecg': 0,\n",
    "    'thalach': 150,\n",
    "    'exang': 0,\n",
    "    'oldpeak': 2.3,\n",
    "    'slope': 0,\n",
    "    'ca': 0,\n",
    "    'thal': 1\n",
    "}\n",
    "\n",
    "resultado1 = predictor.predict(paciente1)\n",
    "print(f\"Resultado: {resultado1['resultado']}\")\n",
    "print(f\"Probabilidade de doença: {resultado1['probabilidade_com_doenca']:.2%}\")\n",
    "print(f\"Confiança: {resultado1['confianca']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb88a503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Predição com lista:\n",
      "Resultado: TEM doença cardíaca\n",
      "Probabilidade de doença: 77.52%\n",
      "Confiança: 77.52%\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 2: Predição com lista (na ordem das features)\n",
    "print(\"\\n2. Predição com lista:\")\n",
    "paciente2 = [67, 1, 0, 160, 286, 0, 0, 108, 1, 1.5, 1, 3, 2]\n",
    "\n",
    "resultado2 = predictor.predict(paciente2)\n",
    "print(f\"Resultado: {resultado2['resultado']}\")\n",
    "print(f\"Probabilidade de doença: {resultado2['probabilidade_com_doenca']:.2%}\")\n",
    "print(f\"Confiança: {resultado2['confianca']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f5f3199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Predição em lote (múltiplos pacientes):\n",
      "\n",
      "Paciente 1: NÃO TEM doença cardíaca (Prob: 1.54%)\n",
      "\n",
      "Paciente 2: NÃO TEM doença cardíaca (Prob: 1.51%)\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 3: Predição em lote (múltiplos pacientes)\n",
    "print(\"\\n3. Predição em lote (múltiplos pacientes):\")\n",
    "pacientes = [\n",
    "    {'age': 54, 'sex': 1, 'cp': 0, 'trestbps': 140, 'chol': 239, 'fbs': 0, \n",
    "     'restecg': 1, 'thalach': 160, 'exang': 0, 'oldpeak': 1.2, 'slope': 0, 'ca': 0, 'thal': 2},\n",
    "    {'age': 41, 'sex': 0, 'cp': 1, 'trestbps': 130, 'chol': 204, 'fbs': 0, \n",
    "     'restecg': 0, 'thalach': 172, 'exang': 0, 'oldpeak': 1.4, 'slope': 2, 'ca': 0, 'thal': 2},\n",
    "]\n",
    "\n",
    "resultados = predictor.predict_batch(pacientes)\n",
    "for i, res in enumerate(resultados, 1):\n",
    "    print(f\"\\nPaciente {i}: {res['resultado']} (Prob: {res['probabilidade_com_doenca']:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4da1201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Para usar este script:\n",
      "1. Importe a classe: from predict import HeartDiseasePredictor\n",
      "2. Crie uma instância: predictor = HeartDiseasePredictor()\n",
      "3. Faça predições: resultado = predictor.predict(features)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Para usar este script:\")\n",
    "print(\"1. Importe a classe: from predict import HeartDiseasePredictor\")\n",
    "print(\"2. Crie uma instância: predictor = HeartDiseasePredictor()\")\n",
    "print(\"3. Faça predições: resultado = predictor.predict(features)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
